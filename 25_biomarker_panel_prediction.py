"""
Biomarker Panel and Prediction Tool Development
ç”Ÿç‰©æ ‡å¿—ç‰©ç»„åˆå’Œé¢„æµ‹å·¥å…·å¼€å‘

åˆ›æ–°ç‚¹ï¼š
1. å¤šæ ‡å¿—ç‰©ç»„åˆä¼˜åŒ–
2. ä¸ªä½“åŒ–é£é™©è¯„ä¼°
3. åŠ¨æ€é¢„æµ‹æ¨¡å‹
4. ä¸´åºŠå†³ç­–æ”¯æŒ
5. å¯è§†åŒ–é¢„æµ‹ç•Œé¢

ä½œè€…ï¼š[Author Names]
æ—¥æœŸï¼š2026-02-03
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression, ElasticNet
from sklearn.svm import SVC
from sklearn.metrics import (accuracy_score, precision_score, recall_score, 
                           f1_score, roc_auc_score, roc_curve,
                           confusion_matrix, classification_report)
from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif
from scipy import stats
from itertools import combinations
import warnings
warnings.filterwarnings('ignore')


class BiomarkerPanel:
    """
    ç”Ÿç‰©æ ‡å¿—ç‰©ç»„åˆç±»
    
    åŠŸèƒ½ï¼š
    - æ ‡å¿—ç‰©é€‰æ‹©
    - ç»„åˆä¼˜åŒ–
    - é£é™©è¯„åˆ†è®¡ç®—
    - é¢„æµ‹æ¨¡å‹æ„å»º
    """
    
    def __init__(self):
        self.biomarkers = None
        self.panel = None
        self.model = None
        self.scaler = StandardScaler()
        self.feature_importance = None
        self.risk_scores = None
        
    def select_biomarkers(self, X: pd.DataFrame, y: pd.Series, 
                        method: str = 'combined', top_n: int = 20):
        """
        é€‰æ‹©ç”Ÿç‰©æ ‡å¿—ç‰©
        
        Parameters:
        -----------
        X : pd.DataFrame
            ç‰¹å¾çŸ©é˜µ
        y : pd.Series
            æ ‡ç­¾
        method : str
            é€‰æ‹©æ–¹æ³• ('univariate', 'multivariate', 'combined')
        top_n : int
            é€‰æ‹©æ ‡å¿—ç‰©æ•°é‡
            
        Returns:
        --------
        pd.DataFrame
            é€‰ä¸­çš„æ ‡å¿—ç‰©åŠå…¶å¾—åˆ†
        """
        print(f"ğŸ” é€‰æ‹©ç”Ÿç‰©æ ‡å¿—ç‰© ({method}, top_n={top_n})...")
        
        results = []
        
        if method in ['univariate', 'combined']:
            # å•å˜é‡åˆ†æ
            print("   å•å˜é‡åˆ†æ...")
            for feature in X.columns:
                group0 = X[y == 0][feature]
                group1 = X[y == 1][feature]
                
                # tæ£€éªŒ
                t_stat, p_value = stats.ttest_ind(group0, group1)
                
                # æ•ˆåº”é‡
                cohens_d = (group1.mean() - group0.mean()) / np.sqrt(
                    (group0.std()**2 + group1.std()**2) / 2
                )
                
                # ROC AUC
                from sklearn.metrics import roc_auc_score
                try:
                    auc = roc_auc_score(y, X[feature])
                except:
                    auc = 0.5
                
                results.append({
                    'Feature': feature,
                    'T_statistic': t_stat,
                    'P_value': p_value,
                    'Cohens_D': cohens_d,
                    'AUC': auc,
                    'Method': 'Univariate'
                })
        
        if method in ['multivariate', 'combined']:
            # å¤šå˜é‡åˆ†æ
            print("   å¤šå˜é‡åˆ†æ...")
            from sklearn.ensemble import RandomForestClassifier
            rf = RandomForestClassifier(n_estimators=100, random_state=42)
            rf.fit(X, y)
            
            for i, feature in enumerate(X.columns):
                results.append({
                    'Feature': feature,
                    'Importance': rf.feature_importances_[i],
                    'Method': 'Multivariate'
                })
        
        # ç»¼åˆè¯„åˆ†
        if method == 'combined':
            # åˆå¹¶å•å˜é‡å’Œå¤šå˜é‡ç»“æœ
            univariate_df = pd.DataFrame([r for r in results if r['Method'] == 'Univariate'])
            multivariate_df = pd.DataFrame([r for r in results if r['Method'] == 'Multivariate'])
            
            # æ ‡å‡†åŒ–å¾—åˆ†
            univariate_df['Score'] = (
                (univariate_df['AUC'] - 0.5) * 2 +  # AUCè½¬æ¢ä¸º-1åˆ°1
                np.abs(univariate_df['Cohens_D']) +   # æ•ˆåº”é‡
                (1 - univariate_df['P_value'])       # æ˜¾è‘—æ€§
            )
            
            multivariate_df['Score'] = multivariate_df['Importance']
            
            # åˆå¹¶
            combined = pd.merge(univariate_df[['Feature', 'Score']], 
                             multivariate_df[['Feature', 'Score']], 
                             on='Feature', suffixes=('_uni', '_multi'))
            combined['Combined_Score'] = combined['Score_uni'] + combined['Score_multi']
            combined = combined.sort_values('Combined_Score', ascending=False).head(top_n)
            
            self.biomarkers = combined
            
        elif method == 'univariate':
            biomarker_df = pd.DataFrame([r for r in results if r['Method'] == 'Univariate'])
            biomarker_df['Score'] = (
                (biomarker_df['AUC'] - 0.5) * 2 +
                np.abs(biomarker_df['Cohens_D']) +
                (1 - biomarker_df['P_value'])
            )
            biomarker_df = biomarker_df.sort_values('Score', ascending=False).head(top_n)
            self.biomarkers = biomarker_df
            
        elif method == 'multivariate':
            biomarker_df = pd.DataFrame([r for r in results if r['Method'] == 'Multivariate'])
            biomarker_df = biomarker_df.sort_values('Importance', ascending=False).head(top_n)
            self.biomarkers = biomarker_df
        
        print(f"   é€‰æ‹©äº† {len(self.biomarkers)} ä¸ªç”Ÿç‰©æ ‡å¿—ç‰©")
        print(f"   Top 5 æ ‡å¿—ç‰©:")
        print(self.biomarkers.head())
        
        return self.biomarkers
    
    def optimize_panel(self, X: pd.DataFrame, y: pd.Series, 
                     max_biomarkers: int = 10, 
                     min_biomarkers: int = 3,
                     metric: str = 'roc_auc'):
        """
        ä¼˜åŒ–æ ‡å¿—ç‰©ç»„åˆ
        
        Parameters:
        -----------
        X : pd.DataFrame
            ç‰¹å¾çŸ©é˜µ
        y : pd.Series
            æ ‡ç­¾
        max_biomarkers : int
            æœ€å¤§æ ‡å¿—ç‰©æ•°
        min_biomarkers : int
            æœ€å°æ ‡å¿—ç‰©æ•°
        metric : str
            è¯„ä¼°æŒ‡æ ‡ ('roc_auc', 'f1', 'accuracy')
            
        Returns:
        --------
        Dict
            æœ€ä¼˜ç»„åˆç»“æœ
        """
        print(f"\nğŸ”§ ä¼˜åŒ–æ ‡å¿—ç‰©ç»„åˆ ({min_biomarkers}-{max_biomarkers} æ ‡å¿—ç‰©)...")
        
        if self.biomarkers is None:
            raise ValueError("è¯·å…ˆé€‰æ‹©ç”Ÿç‰©æ ‡å¿—ç‰©")
        
        candidate_features = self.biomarkers['Feature'].tolist()
        best_score = 0
        best_panel = None
        best_model = None
        
        # å°è¯•ä¸åŒå¤§å°çš„ç»„åˆ
        for n in range(min_biomarkers, min(max_biomarkers + 1, len(candidate_features) + 1)):
            print(f"   æµ‹è¯• {n} ä¸ªæ ‡å¿—ç‰©çš„ç»„åˆ...")
            
            # ä½¿ç”¨è´ªå¿ƒç®—æ³•é€‰æ‹©ç»„åˆ
            current_panel = []
            remaining_features = candidate_features.copy()
            
            for _ in range(n):
                best_feature = None
                best_feature_score = 0
                
                for feature in remaining_features:
                    test_panel = current_panel + [feature]
                    X_panel = X[test_panel]
                    
                    # äº¤å‰éªŒè¯
                    model = RandomForestClassifier(n_estimators=100, random_state=42)
                    cv_scores = cross_val_score(model, X_panel, y, cv=5, scoring=metric)
                    avg_score = cv_scores.mean()
                    
                    if avg_score > best_feature_score:
                        best_feature_score = avg_score
                        best_feature = feature
                
                if best_feature is not None:
                    current_panel.append(best_feature)
                    remaining_features.remove(best_feature)
            
            # è¯„ä¼°å½“å‰ç»„åˆ
            X_panel = X[current_panel]
            model = RandomForestClassifier(n_estimators=100, random_state=42)
            cv_scores = cross_val_score(model, X_panel, y, cv=5, scoring=metric)
            avg_score = cv_scores.mean()
            
            if avg_score > best_score:
                best_score = avg_score
                best_panel = current_panel
                best_model = model
            
            print(f"      {n} æ ‡å¿—ç‰©ç»„åˆ: {metric.upper()} = {avg_score:.4f}")
        
        # è®­ç»ƒæœ€ç»ˆæ¨¡å‹
        X_best = X[best_panel]
        best_model.fit(X_best, y)
        
        self.panel = best_panel
        self.model = best_model
        
        results = {
            'panel': best_panel,
            'n_biomarkers': len(best_panel),
            'score': best_score,
            'model': best_model,
            'feature_names': best_panel
        }
        
        print(f"\nâœ… æœ€ä¼˜ç»„åˆ: {len(best_panel)} ä¸ªæ ‡å¿—ç‰©")
        print(f"   {metric.upper()}: {best_score:.4f}")
        print(f"   æ ‡å¿—ç‰©: {', '.join(best_panel)}")
        
        return results
    
    def calculate_risk_score(self, X: pd.DataFrame, method: str = 'linear'):
        """
        è®¡ç®—é£é™©è¯„åˆ†
        
        Parameters:
        -----------
        X : pd.DataFrame
            ç‰¹å¾çŸ©é˜µ
        method : str
            è®¡ç®—æ–¹æ³• ('linear', 'weighted', 'probability')
            
        Returns:
        --------
        pd.Series
            é£é™©è¯„åˆ†
        """
        print(f"\nğŸ“Š è®¡ç®—é£é™©è¯„åˆ† ({method})...")
        
        if self.panel is None:
            raise ValueError("è¯·å…ˆä¼˜åŒ–æ ‡å¿—ç‰©ç»„åˆ")
        
        X_panel = X[self.panel]
        
        if method == 'linear':
            # çº¿æ€§åŠ æƒ
            if hasattr(self.model, 'coef_'):
                weights = self.model.coef_[0]
            elif hasattr(self.model, 'feature_importances_'):
                weights = self.model.feature_importances_
            else:
                weights = np.ones(len(self.panel))
            
            # å¤„ç†NaNå€¼
            weights = np.nan_to_num(weights, nan=1.0)
            risk_scores = (X_panel * weights).sum(axis=1)
            
        elif method == 'weighted':
            # åŠ æƒæ ‡å‡†åŒ–
            X_scaled = self.scaler.fit_transform(X_panel)
            if hasattr(self.model, 'coef_'):
                weights = self.model.coef_[0]
            elif hasattr(self.model, 'feature_importances_'):
                weights = self.model.feature_importances_
            else:
                weights = np.ones(len(self.panel))
            
            # å¤„ç†NaNå€¼
            weights = np.nan_to_num(weights, nan=1.0)
            risk_scores = (X_scaled * weights).sum(axis=1)
            
        elif method == 'probability':
            # æ¨¡å‹é¢„æµ‹æ¦‚ç‡
            risk_scores = self.model.predict_proba(X_panel)[:, 1]
        
        # å¤„ç†NaNå€¼
        risk_scores = np.nan_to_num(risk_scores, nan=0.0)
        
        # å½’ä¸€åŒ–åˆ°0-100
        score_range = risk_scores.max() - risk_scores.min()
        if score_range > 0:
            risk_scores = (risk_scores - risk_scores.min()) / score_range * 100
        else:
            risk_scores = np.zeros_like(risk_scores) + 50
        
        self.risk_scores = risk_scores
        
        print(f"   é£é™©è¯„åˆ†èŒƒå›´: {risk_scores.min():.2f} - {risk_scores.max():.2f}")
        print(f"   å¹³å‡é£é™©è¯„åˆ†: {risk_scores.mean():.2f}")
        
        return risk_scores
    
    def categorize_risk(self, risk_scores: pd.Series, 
                      thresholds: tuple = (33, 66)):
        """
        é£é™©åˆ†ç±»
        
        Parameters:
        -----------
        risk_scores : pd.Series or np.ndarray
            é£é™©è¯„åˆ†
        thresholds : tuple
            åˆ†ç±»é˜ˆå€¼ (low, high)
            
        Returns:
        --------
        pd.Series
            é£é™©åˆ†ç±»
        """
        low_threshold, high_threshold = thresholds
        
        # è½¬æ¢ä¸ºSeries
        if not isinstance(risk_scores, pd.Series):
            risk_scores = pd.Series(risk_scores)
        
        risk_categories = pd.cut(
            risk_scores,
            bins=[0, low_threshold, high_threshold, 100],
            labels=['Low Risk', 'Medium Risk', 'High Risk']
        )
        
        return risk_categories
    
    def build_prediction_model(self, X: pd.DataFrame, y: pd.Series,
                            model_type: str = 'ensemble'):
        """
        æ„å»ºé¢„æµ‹æ¨¡å‹
        
        Parameters:
        -----------
        X : pd.DataFrame
            ç‰¹å¾çŸ©é˜µ
        y : pd.Series
            æ ‡ç­¾
        model_type : str
            æ¨¡å‹ç±»å‹ ('logistic', 'random_forest', 'gradient_boosting', 'svm', 'ensemble')
            
        Returns:
        --------
        Dict
            æ¨¡å‹æ€§èƒ½
        """
        print(f"\nğŸ¤– æ„å»ºé¢„æµ‹æ¨¡å‹ ({model_type})...")
        
        if self.panel is None:
            raise ValueError("è¯·å…ˆä¼˜åŒ–æ ‡å¿—ç‰©ç»„åˆ")
        
        X_panel = X[self.panel]
        
        # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        X_train, X_test, y_train, y_test = train_test_split(
            X_panel, y, test_size=0.3, random_state=42, stratify=y
        )
        
        # æ ‡å‡†åŒ–
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # æ„å»ºæ¨¡å‹
        if model_type == 'logistic':
            model = LogisticRegression(max_iter=1000, random_state=42)
        elif model_type == 'random_forest':
            model = RandomForestClassifier(n_estimators=200, random_state=42)
        elif model_type == 'gradient_boosting':
            model = GradientBoostingClassifier(n_estimators=200, random_state=42)
        elif model_type == 'svm':
            model = SVC(probability=True, random_state=42)
        elif model_type == 'ensemble':
            from sklearn.ensemble import VotingClassifier
            model = VotingClassifier([
                ('lr', LogisticRegression(max_iter=1000, random_state=42)),
                ('rf', RandomForestClassifier(n_estimators=200, random_state=42)),
                ('gb', GradientBoostingClassifier(n_estimators=200, random_state=42))
            ], voting='soft')
        else:
            raise ValueError(f"æœªçŸ¥çš„æ¨¡å‹ç±»å‹: {model_type}")
        
        # è®­ç»ƒæ¨¡å‹
        model.fit(X_train_scaled, y_train)
        self.model = model
        
        # é¢„æµ‹
        y_pred = model.predict(X_test_scaled)
        y_pred_prob = model.predict_proba(X_test_scaled)[:, 1]
        
        # è¯„ä¼°
        performance = {
            'accuracy': accuracy_score(y_test, y_pred),
            'precision': precision_score(y_test, y_pred),
            'recall': recall_score(y_test, y_pred),
            'f1': f1_score(y_test, y_pred),
            'auc': roc_auc_score(y_test, y_pred_prob)
        }
        
        print(f"   å‡†ç¡®ç‡: {performance['accuracy']:.4f}")
        print(f"   ç²¾ç¡®ç‡: {performance['precision']:.4f}")
        print(f"   å¬å›ç‡: {performance['recall']:.4f}")
        print(f"   F1åˆ†æ•°: {performance['f1']:.4f}")
        print(f"   AUC: {performance['auc']:.4f}")
        
        return performance
    
    def visualize_panel(self, X: pd.DataFrame, y: pd.Series,
                     output_dir: str = './results/biomarker_panel'):
        """
        å¯è§†åŒ–æ ‡å¿—ç‰©ç»„åˆ
        
        Parameters:
        -----------
        X : pd.DataFrame
            ç‰¹å¾çŸ©é˜µ
        y : pd.Series
            æ ‡ç­¾
        output_dir : str
            è¾“å‡ºç›®å½•
        """
        import os
        os.makedirs(output_dir, exist_ok=True)
        
        fig, axes = plt.subplots(3, 3, figsize=(18, 15))
        
        # 1. æ ‡å¿—ç‰©é‡è¦æ€§
        if self.biomarkers is not None:
            ax = axes[0, 0]
            top_biomarkers = self.biomarkers.head(15)
            if 'Combined_Score' in top_biomarkers.columns:
                ax.barh(range(len(top_biomarkers)), top_biomarkers['Combined_Score'])
            elif 'Score' in top_biomarkers.columns:
                ax.barh(range(len(top_biomarkers)), top_biomarkers['Score'])
            else:
                ax.barh(range(len(top_biomarkers)), top_biomarkers['Importance'])
            ax.set_yticks(range(len(top_biomarkers)))
            ax.set_yticklabels(top_biomarkers['Feature'], fontsize=8)
            ax.set_xlabel('Score')
            ax.set_title('Biomarker Importance')
            ax.grid(True, alpha=0.3, axis='x')
        
        # 2. å•ä¸ªæ ‡å¿—ç‰©ROCæ›²çº¿
        if self.biomarkers is not None:
            ax = axes[0, 1]
            from sklearn.metrics import roc_curve, auc
            for feature in self.biomarkers['Feature'].head(5):
                fpr, tpr, _ = roc_curve(y, X[feature])
                roc_auc = auc(fpr, tpr)
                ax.plot(fpr, tpr, label=f'{feature} (AUC={roc_auc:.3f})', linewidth=2)
            ax.plot([0, 1], [0, 1], 'k--', linewidth=1)
            ax.set_xlabel('False Positive Rate')
            ax.set_ylabel('True Positive Rate')
            ax.set_title('Individual Biomarker ROC Curves')
            ax.legend(fontsize=6)
            ax.grid(True, alpha=0.3)
        
        # 3. æ ‡å¿—ç‰©åˆ†å¸ƒç®±çº¿å›¾
        if self.panel is not None:
            ax = axes[0, 2]
            X_panel = X[self.panel]
            n_show = min(5, len(self.panel))
            for i, biomarker in enumerate(self.panel[:n_show]):
                data0 = X_panel[y == 0][biomarker].values
                data1 = X_panel[y == 1][biomarker].values
                positions = [i*2 + 0.5, i*2 + 1.5]
                bp = ax.boxplot([data0, data1], positions=positions, widths=0.8, patch_artist=True)
                bp['boxes'][0].set_facecolor('lightblue')
                bp['boxes'][1].set_facecolor('lightcoral')
            ax.set_xticks(range(2, n_show*2 + 1, 2))
            ax.set_xticklabels(self.panel[:n_show], rotation=15, ha='right')
            ax.set_ylabel('Value')
            ax.set_title('Biomarker Distribution by Group')
            ax.legend(['Control', 'AD'], loc='upper right')
        
        # 4. æ ‡å¿—ç‰©ç›¸å…³æ€§çƒ­å›¾
        if self.panel is not None:
            ax = axes[1, 0]
            X_panel = X[self.panel]
            corr_matrix = X_panel.corr()
            sns.heatmap(corr_matrix, cmap='coolwarm', center=0,
                       ax=ax, cbar_kws={'label': 'Correlation'})
            ax.set_title('Biomarker Correlation Heatmap')
        
        # 5. ç»„åˆROCæ›²çº¿
        if self.model is not None and self.panel is not None:
            ax = axes[1, 1]
            X_panel = X[self.panel]
            X_scaled = self.scaler.transform(X_panel)
            y_pred_prob = self.model.predict_proba(X_scaled)[:, 1]
            fpr, tpr, _ = roc_curve(y, y_pred_prob)
            roc_auc = auc(fpr, tpr)
            ax.plot(fpr, tpr, linewidth=2, label=f'Panel (AUC={roc_auc:.3f})')
            ax.plot([0, 1], [0, 1], 'k--', linewidth=1)
            ax.set_xlabel('False Positive Rate')
            ax.set_ylabel('True Positive Rate')
            ax.set_title('Combined Panel ROC Curve')
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        # 6. é£é™©è¯„åˆ†åˆ†å¸ƒ
        if self.risk_scores is not None:
            ax = axes[1, 2]
            ax.hist(self.risk_scores[y == 0], bins=30, alpha=0.6, 
                   label='Control', color='blue')
            ax.hist(self.risk_scores[y == 1], bins=30, alpha=0.6, 
                   label='AD', color='red')
            ax.set_xlabel('Risk Score')
            ax.set_ylabel('Frequency')
            ax.set_title('Risk Score Distribution')
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        # 7. é£é™©åˆ†ç±»
        if self.risk_scores is not None:
            ax = axes[2, 0]
            risk_categories = self.categorize_risk(self.risk_scores)
            category_counts = risk_categories.value_counts()
            colors = ['green', 'orange', 'red']
            ax.pie(category_counts.values, labels=category_counts.index, 
                   autopct='%1.1f%%', colors=colors)
            ax.set_title('Risk Category Distribution')
        
        # 8. æ··æ·†çŸ©é˜µ
        if self.model is not None and self.panel is not None:
            ax = axes[2, 1]
            X_panel = X[self.panel]
            X_scaled = self.scaler.transform(X_panel)
            y_pred = self.model.predict(X_scaled)
            cm = confusion_matrix(y, y_pred)
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,
                       cbar_kws={'label': 'Count'})
            ax.set_xlabel('Predicted')
            ax.set_ylabel('Actual')
            ax.set_title('Confusion Matrix')
        
        # 9. æ ‡å¿—ç‰©ç»„åˆæ‘˜è¦
        ax = axes[2, 2]
        ax.axis('off')
        
        summary_text = "Biomarker Panel Summary\n\n"
        
        if self.panel is not None:
            summary_text += f"Panel Size: {len(self.panel)} biomarkers\n\n"
            summary_text += "Biomarkers:\n"
            for i, biomarker in enumerate(self.panel, 1):
                summary_text += f"{i}. {biomarker}\n"
        
        if self.model is not None:
            X_panel = X[self.panel]
            X_scaled = self.scaler.transform(X_panel)
            y_pred = self.model.predict(X_scaled)
            accuracy = accuracy_score(y, y_pred)
            summary_text += f"\nModel Accuracy: {accuracy:.2%}\n"
        
        if self.risk_scores is not None:
            summary_text += f"\nRisk Score Range: {self.risk_scores.min():.1f} - {self.risk_scores.max():.1f}\n"
            summary_text += f"Mean Risk Score: {self.risk_scores.mean():.1f}\n"
        
        ax.text(0.1, 0.9, summary_text, transform=ax.transAxes,
               fontsize=10, verticalalignment='top', family='monospace')
        
        plt.tight_layout()
        plt.savefig(f'{output_dir}/biomarker_panel.png', dpi=300, bbox_inches='tight')
        print(f"âœ… æ ‡å¿—ç‰©ç»„åˆå¯è§†åŒ–ä¿å­˜åˆ°: {output_dir}/biomarker_panel.png")
        
        plt.close()


class IndividualRiskAssessment:
    """
    ä¸ªä½“åŒ–é£é™©è¯„ä¼°ç±»
    
    åŠŸèƒ½ï¼š
    - ä¸ªä½“é£é™©è®¡ç®—
    - é£é™©å› ç´ åˆ†æ
    - é¢„é˜²å»ºè®®ç”Ÿæˆ
    """
    
    def __init__(self, biomarker_panel: BiomarkerPanel):
        self.panel = biomarker_panel
        
    def assess_individual(self, individual_data: pd.DataFrame):
        """
        è¯„ä¼°ä¸ªä½“é£é™©
        
        Parameters:
        -----------
        individual_data : pd.DataFrame
            ä¸ªä½“æ•°æ®
            
        Returns:
        --------
        Dict
            é£é™©è¯„ä¼°ç»“æœ
        """
        print("\nğŸ‘¤ ä¸ªä½“åŒ–é£é™©è¯„ä¼°...")
        
        # è®¡ç®—é£é™©è¯„åˆ†ï¼ˆä½¿ç”¨probabilityæ–¹æ³•ï¼Œå› ä¸ºé›†æˆæ¨¡å‹æ”¯æŒï¼‰
        risk_score = self.panel.calculate_risk_score(individual_data, method='probability')
        
        # é£é™©åˆ†ç±»
        risk_category = self.panel.categorize_risk(risk_score)
        
        # é£é™©å› ç´ åˆ†æ
        risk_factors = self._analyze_risk_factors(individual_data)
        
        # ç”Ÿæˆå»ºè®®
        recommendations = self._generate_recommendations(risk_category, risk_factors)
        
        # å¤„ç†è¿”å›å€¼
        if hasattr(risk_score, 'iloc'):
            risk_score_value = risk_score.iloc[0]
        else:
            risk_score_value = risk_score[0] if len(risk_score) > 0 else 0
        
        if hasattr(risk_category, 'iloc'):
            risk_category_value = risk_category.iloc[0]
        else:
            risk_category_value = risk_category
        
        results = {
            'risk_score': risk_score_value,
            'risk_category': risk_category_value,
            'risk_factors': risk_factors,
            'recommendations': recommendations
        }
        
        print(f"   é£é™©è¯„åˆ†: {risk_score_value:.2f}")
        print(f"   é£é™©åˆ†ç±»: {risk_category_value}")
        
        return results
    
    def _analyze_risk_factors(self, individual_data: pd.DataFrame):
        """
        åˆ†æé£é™©å› ç´ 
        """
        risk_factors = []
        
        if self.panel.panel is not None:
            for biomarker in self.panel.panel:
                value = individual_data[biomarker].iloc[0]
                # ç®€åŒ–çš„é£é™©å› ç´ åˆ¤æ–­
                if value > individual_data[biomarker].quantile(0.75):
                    risk_level = 'High'
                elif value > individual_data[biomarker].quantile(0.5):
                    risk_level = 'Medium'
                else:
                    risk_level = 'Low'
                
                risk_factors.append({
                    'Biomarker': biomarker,
                    'Value': value,
                    'Risk_Level': risk_level
                })
        
        return risk_factors
    
    def _generate_recommendations(self, risk_category, risk_factors: list):
        """
        ç”Ÿæˆé¢„é˜²å»ºè®®
        """
        recommendations = []
        
        # å¤„ç†pandas Series
        if hasattr(risk_category, 'iloc'):
            risk_category_str = risk_category.iloc[0]
        else:
            risk_category_str = risk_category
        
        if risk_category_str == 'High Risk':
            recommendations.append("å»ºè®®è¿›è¡Œè¿›ä¸€æ­¥ä¸´åºŠæ£€æŸ¥")
            recommendations.append("è€ƒè™‘ç”Ÿæ´»æ–¹å¼å¹²é¢„")
            recommendations.append("å®šæœŸç›‘æµ‹ç›¸å…³æŒ‡æ ‡")
        elif risk_category_str == 'Medium Risk':
            recommendations.append("å»ºè®®å®šæœŸéšè®¿")
            recommendations.append("ä¿æŒå¥åº·ç”Ÿæ´»æ–¹å¼")
            recommendations.append("å…³æ³¨ç›¸å…³æŒ‡æ ‡å˜åŒ–")
        else:
            recommendations.append("ç»§ç»­ä¿æŒå¥åº·ç”Ÿæ´»æ–¹å¼")
            recommendations.append("å®šæœŸä½“æ£€")
        
        return recommendations


def demo_biomarker_panel():
    """
    æ¼”ç¤ºç”Ÿç‰©æ ‡å¿—ç‰©ç»„åˆå¼€å‘
    """
    print("=" * 60)
    print("ç”Ÿç‰©æ ‡å¿—ç‰©ç»„åˆå’Œé¢„æµ‹å·¥å…·å¼€å‘")
    print("=" * 60)
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)
    n_samples = 300
    n_features = 50
    
    X = pd.DataFrame(
        np.random.randn(n_samples, n_features),
        columns=[f'Biomarker_{i}' for i in range(n_features)]
    )
    
    # åˆ›å»ºæ ‡ç­¾ï¼ˆAD vs Controlï¼‰
    y = pd.Series(
        np.random.choice([0, 1], n_samples, p=[0.6, 0.4])
    )
    
    # åˆ›å»ºç”Ÿç‰©æ ‡å¿—ç‰©ç»„åˆåˆ†æå™¨
    panel_analyzer = BiomarkerPanel()
    
    # é€‰æ‹©ç”Ÿç‰©æ ‡å¿—ç‰©
    biomarkers = panel_analyzer.select_biomarkers(X, y, method='combined', top_n=20)
    
    # ä¼˜åŒ–æ ‡å¿—ç‰©ç»„åˆ
    optimized_panel = panel_analyzer.optimize_panel(X, y, max_biomarkers=10, min_biomarkers=3)
    
    # è®¡ç®—é£é™©è¯„åˆ†
    risk_scores = panel_analyzer.calculate_risk_score(X, method='probability')
    
    # æ„å»ºé¢„æµ‹æ¨¡å‹
    performance = panel_analyzer.build_prediction_model(X, y, model_type='ensemble')
    
    # å¯è§†åŒ–
    panel_analyzer.visualize_panel(X, y)
    
    # ä¸ªä½“åŒ–é£é™©è¯„ä¼°
    individual_assessor = IndividualRiskAssessment(panel_analyzer)
    individual_data = X.iloc[[0]]
    assessment = individual_assessor.assess_individual(individual_data)
    
    print("\n" + "=" * 60)
    print("âœ… ç”Ÿç‰©æ ‡å¿—ç‰©ç»„åˆå¼€å‘æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 60)


if __name__ == '__main__':
    demo_biomarker_panel()
